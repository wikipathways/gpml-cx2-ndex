{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This workflow automates the publication of WikiPathways networks to NDEx."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Required Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### py4cytoscape: https://github.com/cytoscape/py4cytoscape\n",
    "#### ndex2 client: https://github.com/ndexbio/ndex2-client/tree/master\n",
    "#### pywikipathways: https://github.com/wikipathways/pywikipathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import urllib\n",
    "import urllib.parse\n",
    "\n",
    "import ndex2\n",
    "from ndex2.client import DecimalEncoder\n",
    "from ndex2.cx2 import RawCX2NetworkFactory\n",
    "import py4cytoscape as p4c\n",
    "import pywikipathways as pyw\n",
    "from requests import HTTPError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Use Cytoscape to convert GPML to CX2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download wikipathway networks from https://github.com/wikipathways/wikipathways-data-release in GPML format.\n",
    "#### Open Cytoscape. Run the code below to convert all GPML files to CX2 files, and save all CX2 files in a new folder.\n",
    "#### In the future, we can use https://github.com/wikipathways/gpml-to-cx2 to run this workflow without Cytoscape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"wikipathways-20250310-gpml-Homo_sapiens\"\n",
    "output_dir = \"wikipathways-20250310-cx2-Homo_sapiens\"\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith(\".gpml\"):\n",
    "        input_filepath = os.path.join(input_dir, filename)\n",
    "        try:\n",
    "            p4c.import_network_from_file(input_filepath)\n",
    "        except Exception as e:\n",
    "            if \"this.largeNetworks\" in str(e):\n",
    "                print(f\"Known error encountered in {filename}, skipping.\")\n",
    "                export_filepath = os.path.join(output_dir, filename)\n",
    "                p4c.export_network(filename=export_filepath, type='cx2')\n",
    "                p4c.delete_all_networks()\n",
    "                continue\n",
    "            else:\n",
    "                raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rename file names to network names we use in NDEx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = output_dir\n",
    "\n",
    "species_map = {\n",
    "    \"Hs\": \"Homo sapiens\",\n",
    "}\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".cx2\"):\n",
    "        if filename.endswith(\".gpml.cx2\"):\n",
    "            base_name = filename[:-len(\".gpml.cx2\")]\n",
    "        else:\n",
    "            base_name = filename[:-len(\".cx2\")]\n",
    "        \n",
    "        parts = base_name.split(\"_\")\n",
    "        if len(parts) < 4:\n",
    "            print(f\"Filename '{filename}' does not conform to the expected pattern. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        species_abbr = parts[0]\n",
    "        species_full = species_map.get(species_abbr, species_abbr)\n",
    "\n",
    "        wp_id = parts[-2]\n",
    "\n",
    "        description_tokens = parts[1:-2]\n",
    "        description = \" \".join(description_tokens)\n",
    "\n",
    "        new_filename = f\"{wp_id} - {description} - {species_full}.cx2\"\n",
    "        \n",
    "        old_path = os.path.join(directory, filename)\n",
    "        new_path = os.path.join(directory, new_filename)\n",
    "\n",
    "        os.rename(old_path, new_path)\n",
    "        print(f\"Renamed '{filename}' to '{new_filename}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Update existing networks and upload new networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use ndex2 library to build connection to ndex server. This only need to be run once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = ndex2.client.Ndex2(username='username', password='password')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This UUID is wikipathway network set ID, and this ID can be found in NDEx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "networks_id_list = client.get_networkset(\"453c1c63-5c10-11e9-9f06-0ac135e8bacf\")['networks']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get existing wikipathway networks in NDEx, since these networks need to be updated with client.update_cx2_network()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_directory = output_dir\n",
    "\n",
    "local_wpids = set()\n",
    "for fname in os.listdir(local_directory):\n",
    "    if fname.endswith(\".cx2\"):\n",
    "        base = fname[:-len(\".cx2\")]\n",
    "        wpid = base.split(\" - \")[0]\n",
    "        local_wpids.add(wpid)\n",
    "\n",
    "common_networks = []\n",
    "for net_id in networks_id_list:\n",
    "    summary = client.get_network_summary(net_id)\n",
    "    network_name = summary['name']\n",
    "    wpid = network_name.split(\" - \")[0]\n",
    "    if wpid in local_wpids:\n",
    "        common_networks.append({\"id\": net_id, \"name\": network_name})\n",
    "\n",
    "print(\"Networks present in both the result list and local folder:\")\n",
    "for net in common_networks:\n",
    "    print(f\"ID: {net['id']}, Name: {net['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get new wikipathway networks and they are not in NDEx, and these networks need to be uploade with client.save_new_cx2_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_wpids = set()\n",
    "for net_id in networks_id_list:\n",
    "    summary = client.get_network_summary(net_id)\n",
    "    network_name = summary['name']\n",
    "    wpid = network_name.split(\" - \")[0]\n",
    "    network_wpids.add(wpid)\n",
    "\n",
    "new_networks = []\n",
    "for fname in os.listdir(local_directory):\n",
    "    if fname.endswith(\".cx2\"):\n",
    "        base = fname[:-len(\".cx2\")]\n",
    "        local_wpid = base.split(\" - \")[0]\n",
    "        if local_wpid not in network_wpids:\n",
    "            new_networks.append(fname)\n",
    "\n",
    "print(\"Local networks that do not exist in the network_id_list:\")\n",
    "for network in new_networks:\n",
    "    print(network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pywikipathway library is used here to get additional network information, which will be used in network properties in NDEx."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Updating existed network..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cx2_folder = output_dir\n",
    "\n",
    "if not os.path.isdir(cx2_folder):\n",
    "    print(f\"Error: Directory '{cx2_folder}' not found. Check the folder name or path.\")\n",
    "    exit(1)\n",
    "\n",
    "all_files = os.listdir(cx2_folder)\n",
    "\n",
    "for network in common_networks:\n",
    "    network_id = network.get('id')\n",
    "    network_name = network.get('name')\n",
    "    \n",
    "    if not network_name:\n",
    "        print(f\"Skipping network with id {network_id} because it has no name.\")\n",
    "        continue\n",
    "\n",
    "        \n",
    "    match = re.search(r\"(WP\\d+)\", network_name)\n",
    "    fwpid = match.group(1) if match else \"\"\n",
    "\n",
    "    if not wpid:\n",
    "        print(f\"Skipping network {network_name} because no WPID could be extracted.\")\n",
    "        continue\n",
    "\n",
    "    pattern = re.compile(r'(?<!\\d)' + re.escape(wpid) + r'(?!\\d)', re.IGNORECASE)\n",
    "\n",
    "    candidates = [f for f in all_files if pattern.search(f) and f.endswith(\".cx2\")]\n",
    "    if not candidates:\n",
    "        print(f\"No file found for WPID {wpid} in {cx2_folder}. Skipping network {network_name}.\")\n",
    "        continue\n",
    "\n",
    "    file_path = os.path.join(cx2_folder, candidates[0])\n",
    "    print(f\"Processing file: {file_path} for network {network_name} (WPID: {wpid})\")\n",
    "\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    for item in data:\n",
    "        if isinstance(item, dict) and 'networkAttributes' in item:\n",
    "            for attr in item['networkAttributes']:\n",
    "                attr['name'] = f\"{wpid} - {attr.get('name', '')}\"\n",
    "    \n",
    "    factory = RawCX2NetworkFactory()\n",
    "    net = factory.get_cx2network(data)\n",
    "    net_attrs = net.get_network_attributes()\n",
    "    \n",
    "    onto_info = pyw.wikipathways_get('getOntologyTermsByPathway', {'pwId': wpid, 'format': 'json'})\n",
    "    if onto_info is None:\n",
    "        print(f\"Warning: No ontology info returned for WPID {wpid}. Proceeding with an empty terms list.\")\n",
    "        onto_info = {\"terms\": []}\n",
    "\n",
    "    base_url_pw = \"https://www.ebi.ac.uk/ols4/ontologies/pw/classes?obo_id=\"\n",
    "    labels_html_pw = []\n",
    "    for term in onto_info.get(\"terms\", []):\n",
    "        if term.get(\"ontology\") == \"Pathway Ontology\":\n",
    "            term_id = term.get(\"id\")\n",
    "            term_name = term.get(\"name\")\n",
    "            if term_id and term_name:\n",
    "                term_id_encoded = urllib.parse.quote(term_id, safe='')\n",
    "                hyperlink = f'<a href=\"{base_url_pw}{term_id_encoded}\">{term_name}</a>'\n",
    "                labels_html_pw.append(hyperlink)\n",
    "    if labels_html_pw:\n",
    "        net_attrs[\"Labels\"] = \", \".join(labels_html_pw)\n",
    "    \n",
    "    base_url_cl = \"https://www.ebi.ac.uk/ols4/ontologies/cl/classes?obo_id=\"\n",
    "    labels_html_cl = []\n",
    "    for term in onto_info.get(\"terms\", []):\n",
    "        if term.get(\"ontology\") == \"Cell Type\":\n",
    "            term_id = term.get(\"id\")\n",
    "            term_name = term.get(\"name\")\n",
    "            if term_id and term_name:\n",
    "                term_id_encoded = urllib.parse.quote(term_id, safe='')\n",
    "                hyperlink = f'<a href=\"{base_url_cl}{term_id_encoded}\">{term_name}</a>'\n",
    "                labels_html_cl.append(hyperlink)\n",
    "    if labels_html_cl:\n",
    "        net_attrs[\"Cell\"] = \", \".join(labels_html_cl)\n",
    "    \n",
    "    base_url_doid = \"https://www.ebi.ac.uk/ols4/ontologies/doid/classes?obo_id=\"\n",
    "    labels_html_doid = []\n",
    "    for term in onto_info.get(\"terms\", []):\n",
    "        if term.get(\"ontology\") == \"Disease\":\n",
    "            term_id = term.get(\"id\")\n",
    "            term_name = term.get(\"name\")\n",
    "            if term_id and term_name:\n",
    "                term_id_encoded = urllib.parse.quote(term_id, safe='')\n",
    "                hyperlink = f'<a href=\"{base_url_doid}{term_id_encoded}\">{term_name}</a>'\n",
    "                labels_html_doid.append(hyperlink)\n",
    "    if labels_html_doid:\n",
    "        net_attrs[\"Disease\"] = \", \".join(labels_html_doid)\n",
    "    \n",
    "    net_attrs['author'] = 'WikiPathways team'\n",
    "    net_attrs['version'] = '20250407'\n",
    "    net_attrs['WikipathwaysID'] = wpid\n",
    "    net_attrs['WikipathwaysIRI'] = f'<a href=\"http://identifiers.org/wikipathways/{wpid}\">http://identifiers.org/wikipathways/{wpid}</a>'\n",
    "    net_attrs['NetworkType'] = 'pathway'\n",
    "    \n",
    "    net.set_network_attributes(net_attrs)\n",
    "    \n",
    "    cx_stream = io.BytesIO(json.dumps(net.to_cx2(), cls=DecimalEncoder).encode('utf-8'))\n",
    "    \n",
    "    client.set_read_only(network_id, False)\n",
    "    res = client.update_cx2_network(cx_stream, network_id)\n",
    "    \n",
    "    max_retries = 3\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            client.set_read_only(network_id, True)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt+1} to set network as read-only failed: {e}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(2)\n",
    "            else:\n",
    "                print(\"Max retry attempts reached. Could not set network as read-only.\")\n",
    "                raise\n",
    "    \n",
    "    print(f\"Successfully processed network: {network_name} (WPID: {wpid}) with id {network_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uploading new networks..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cx2_folder = output_dir\n",
    "\n",
    "if not os.path.isdir(cx2_folder):\n",
    "    print(f\"Error: Directory '{cx2_folder}' not found. Check the folder name or path.\")\n",
    "    exit(1)\n",
    "\n",
    "for fn in new_networks:\n",
    "    file_path = os.path.join(cx2_folder, fn)\n",
    "    \n",
    "    file_name = os.path.basename(file_path)\n",
    "    match = re.match(r\"(WP\\d+)\\s*-\", file_name)\n",
    "    prefix = match.group(1) if match else \"\"\n",
    "    \n",
    "    if not prefix:\n",
    "        print(f\"Skipping file {file_name} because no WPID could be extracted.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Processing file: {file_path} (WPID: {prefix})\")\n",
    "    \n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    for item in data:\n",
    "        if isinstance(item, dict) and 'networkAttributes' in item:\n",
    "            for attr in item['networkAttributes']:\n",
    "                attr['name'] = f\"{prefix} - {attr.get('name', '')}\"\n",
    "    \n",
    "    factory = RawCX2NetworkFactory()\n",
    "    net = factory.get_cx2network(data)\n",
    "    net_attrs = net.get_network_attributes()\n",
    "    \n",
    "    onto_info = pyw.wikipathways_get('getOntologyTermsByPathway', {'pwId': prefix, 'format': 'json'})\n",
    "    \n",
    "    base_url_pw = \"https://www.ebi.ac.uk/ols4/ontologies/pw/classes?obo_id=\"\n",
    "    labels_html = []\n",
    "    for term in onto_info.get(\"terms\", []):\n",
    "        if term.get(\"ontology\") == \"Pathway Ontology\":\n",
    "            term_id = term.get(\"id\")\n",
    "            term_name = term.get(\"name\")\n",
    "            if term_id and term_name:\n",
    "                term_id_encoded = urllib.parse.quote(term_id, safe='')\n",
    "                hyperlink = f'<a href=\"{base_url_pw}{term_id_encoded}\">{term_name}</a>'\n",
    "                labels_html.append(hyperlink)\n",
    "    if labels_html:\n",
    "        net_attrs[\"Labels\"] = \", \".join(labels_html)\n",
    "    \n",
    "    base_url_cl = \"https://www.ebi.ac.uk/ols4/ontologies/cl/classes?obo_id=\"\n",
    "    labels_html = []\n",
    "    for term in onto_info.get(\"terms\", []):\n",
    "        if term.get(\"ontology\") == \"Cell Type\":\n",
    "            term_id = term.get(\"id\")\n",
    "            term_name = term.get(\"name\")\n",
    "            if term_id and term_name:\n",
    "                term_id_encoded = urllib.parse.quote(term_id, safe='')\n",
    "                hyperlink = f'<a href=\"{base_url_cl}{term_id_encoded}\">{term_name}</a>'\n",
    "                labels_html.append(hyperlink)\n",
    "    if labels_html:\n",
    "        net_attrs[\"Cell\"] = \", \".join(labels_html)\n",
    "    \n",
    "    base_url_doid = \"https://www.ebi.ac.uk/ols4/ontologies/doid/classes?obo_id=\"\n",
    "    labels_html = []\n",
    "    for term in onto_info.get(\"terms\", []):\n",
    "        if term.get(\"ontology\") == \"Disease\":\n",
    "            term_id = term.get(\"id\")\n",
    "            term_name = term.get(\"name\")\n",
    "            if term_id and term_name:\n",
    "                term_id_encoded = urllib.parse.quote(term_id, safe='')\n",
    "                hyperlink = f'<a href=\"{base_url_doid}{term_id_encoded}\">{term_name}</a>'\n",
    "                labels_html.append(hyperlink)\n",
    "    if labels_html:\n",
    "        net_attrs[\"Disease\"] = \", \".join(labels_html)\n",
    "    \n",
    "    net_attrs['author'] = 'WikiPathways team'\n",
    "    net_attrs['version'] = '20250407'\n",
    "    net_attrs['WikipathwaysID'] = prefix\n",
    "    net_attrs['WikipathwaysIRI'] = f'<a href=\"http://identifiers.org/wikipathways/{prefix}\">http://identifiers.org/wikipathways/{prefix}</a>'\n",
    "    net_attrs['NetworkType'] = 'pathway'\n",
    "    \n",
    "    net.set_network_attributes(net_attrs)\n",
    "    \n",
    "    res = client.save_new_cx2_network(net.to_cx2(), \"PUBLIC\")\n",
    "    uuid_match = re.search(\n",
    "        r'([0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12})',\n",
    "        res\n",
    "    )\n",
    "    if uuid_match:\n",
    "        uuid = uuid_match.group(1)\n",
    "    else:\n",
    "        print(f\"Could not extract UUID from response for network {prefix}\")\n",
    "        continue\n",
    "    \n",
    "    client.set_read_only(uuid, True)\n",
    "    \n",
    "    print(f\"Successfully processed network with WPID: {prefix} and UUID: {uuid}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Add hyperlink to ChEBI and Ensembl in node table for all networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get all networks UUID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uuid_list = client.get_networkset('453c1c63-5c10-11e9-9f06-0ac135e8bacf')['networks']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add url in @context, NDEx server will make the url clickable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cx_context = {\n",
    "    \"signor\": \"http://signor.uniroma2.it/relation_result.php?id=\",\n",
    "    \"BTO\": \"http://identifiers.org/bto/BTO:\",\n",
    "    \"uniprot\": \"http://identifiers.org/uniprot/\",\n",
    "    \"pubmed\": \"http://identifiers.org/pubmed/\",\n",
    "    \"CID\": \"http://identifiers.org/pubchem.compound/\",\n",
    "    \"SID\": \"http://identifiers.org/pubchem.substance/\",\n",
    "    \"chebi\": \"http://identifiers.org/chebi/CHEBI:\",\n",
    "    \"hgnc.symbol\": \"http://identifiers.org/hgnc.symbol/\",\n",
    "    \"Ensembl\":\"http://identifiers.org/ensembl:\"\n",
    "}\n",
    "\n",
    "\n",
    "def retry_on_500(func, *args, retries=3, backoff=1, **kwargs):\n",
    "    attempt = 0\n",
    "    while True:\n",
    "        try:\n",
    "            return func(*args, **kwargs)\n",
    "        except HTTPError as e:\n",
    "            status = getattr(e.response, \"status_code\", None)\n",
    "            if status == 500 and attempt < retries:\n",
    "                attempt += 1\n",
    "                time.sleep(backoff)\n",
    "                backoff *= 2\n",
    "                continue\n",
    "            raise\n",
    "            \n",
    "def prefix_cx_context(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        new = {}\n",
    "        for k, v in obj.items():\n",
    "            if k == \"Ensembl\" and isinstance(v, str):\n",
    "                new[k] = f\"Ensembl:{v}\"\n",
    "            else:\n",
    "                new[k] = prefix_cx_context(v)\n",
    "        return new\n",
    "    elif isinstance(obj, list):\n",
    "        return [prefix_cx_context(item) for item in obj]\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "\n",
    "\n",
    "for uid in uuid_list:\n",
    "    retry_on_500(client.set_read_only, uid, False)\n",
    "\n",
    "    resp = retry_on_500(client.get_network_as_cx2_stream, uid)\n",
    "    net_cx = factory.get_cx2network(prefix_cx_context(json.loads(resp.content)))\n",
    "\n",
    "    net_attrs = net_cx.get_network_attributes()\n",
    "    net_attrs['@context'] = json.dumps(cx_context)\n",
    "    net_cx.set_network_attributes(net_attrs)\n",
    "    \n",
    "    payload = json.dumps(net_cx.to_cx2(), cls=DecimalEncoder).encode('utf-8')\n",
    "    cx_stream = io.BytesIO(payload)\n",
    "    retry_on_500(client.update_cx2_network, cx_stream, uid)\n",
    "\n",
    "    retry_on_500(client.set_read_only, uid, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some outdated networks need to be delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_networks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_networks_from_networkset('453c1c63-5c10-11e9-9f06-0ac135e8bacf', delete_networks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After finishing the workflow, go to NDEx, and double check that all wikipathway networks are READ ONLY."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Plan\n",
    "#### Use Github action to run this workflow every month."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
